{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng vá»›i tÃ i khoáº£n: nphuc\n",
      "ğŸ“š Äang Ä‘á»c file JSON...\n",
      "â¬†ï¸ Äang Ä‘Äƒng táº£i dataset lÃªn Hugging Face...\n",
      "âš ï¸ Repository cÃ³ thá»ƒ Ä‘Ã£ tá»“n táº¡i: HfApi.create_repo() got an unexpected keyword argument 'description'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 208.16ba/s]\n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset Ä‘Ã£ Ä‘Æ°á»£c Ä‘Äƒng táº£i thÃ nh cÃ´ng táº¡i: https://huggingface.co/datasets/nphuc/output_samples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import HfApi, create_repo, login\n",
    "from typing import Dict, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class HuggingFaceDatasetCreator:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Khá»Ÿi táº¡o vá»›i token tá»« biáº¿n mÃ´i trÆ°á»ng hoáº·c cache\n",
    "        \"\"\"\n",
    "        # Load biáº¿n mÃ´i trÆ°á»ng\n",
    "        load_dotenv(override=True)\n",
    "        \n",
    "        # Thá»­ láº¥y token tá»« biáº¿n mÃ´i trÆ°á»ng\n",
    "        self.token = os.getenv('HF_TOKEN')\n",
    "        \n",
    "        if not self.token:\n",
    "            raise ValueError(\"KhÃ´ng tÃ¬m tháº¥y token. HÃ£y cháº¡y 'huggingface-cli login' hoáº·c thÃªm HF_TOKEN vÃ o file .env\")\n",
    "            \n",
    "        # Login vÃ o Hugging Face\n",
    "        try:\n",
    "            self.api = HfApi(token=self.token)\n",
    "            # Kiá»ƒm tra token cÃ³ há»£p lá»‡ khÃ´ng\n",
    "            user_info = self.api.whoami()\n",
    "            print(f\"âœ… ÄÄƒng nháº­p thÃ nh cÃ´ng vá»›i tÃ i khoáº£n: {user_info['name']}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Lá»—i Ä‘Äƒng nháº­p: {str(e)}\")\n",
    "    \n",
    "    def read_json_dataset(self, file_path: str) -> Dict[str, List]:\n",
    "        \"\"\"\n",
    "        Äá»c file JSON dataset theo format Alpaca\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                \n",
    "            formatted_data = {\n",
    "                'instruction': [],\n",
    "                'input': [],\n",
    "                'output': []\n",
    "            }\n",
    "            \n",
    "            for item in data:\n",
    "                formatted_data['instruction'].append(item['instruction'])\n",
    "                formatted_data['input'].append(item['input'])\n",
    "                formatted_data['output'].append(item['output'])\n",
    "                \n",
    "            return formatted_data\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Lá»—i Ä‘á»c file JSON: {str(e)}\")\n",
    "    \n",
    "    def create_and_push_dataset(self, data: Dict[str, List], json_file: str, description: str = None):\n",
    "        \"\"\"\n",
    "        Táº¡o vÃ  Ä‘áº©y dataset lÃªn Hugging Face Hub\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Táº¡o dataset\n",
    "            dataset = Dataset.from_dict(data)\n",
    "            \n",
    "            # Láº¥y thÃ´ng tin repository tá»« biáº¿n mÃ´i trÆ°á»ng\n",
    "            username = os.getenv('HF_USERNAME')\n",
    "            \n",
    "            # Láº¥y tÃªn dataset tá»« tÃªn file JSON (khÃ´ng cÃ³ pháº§n má»Ÿ rá»™ng)\n",
    "            dataset_name = os.path.splitext(os.path.basename(json_file))[0]\n",
    "            \n",
    "            if not username or not dataset_name:\n",
    "                raise ValueError(\"Thiáº¿u HF_USERNAME trong file .env\")\n",
    "                \n",
    "            repo_name = f\"{username}/{dataset_name}\"\n",
    "            \n",
    "            # Táº¡o repository\n",
    "            try:\n",
    "                create_repo(\n",
    "                    repo_id=repo_name,\n",
    "                    repo_type=\"dataset\",\n",
    "                    private=True,\n",
    "                    token=self.token,\n",
    "                    description=description\n",
    "                )\n",
    "                print(f\"âœ… ÄÃ£ táº¡o repository: {repo_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Repository cÃ³ thá»ƒ Ä‘Ã£ tá»“n táº¡i: {str(e)}\")\n",
    "            \n",
    "            # Äáº©y dataset lÃªn hub\n",
    "            dataset.push_to_hub(repo_name, token=self.token)\n",
    "            \n",
    "            print(f\"âœ… Dataset Ä‘Ã£ Ä‘Æ°á»£c Ä‘Äƒng táº£i thÃ nh cÃ´ng táº¡i: https://huggingface.co/datasets/{repo_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Lá»—i khi táº¡o vÃ  Ä‘áº©y dataset: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Cáº¥u hÃ¬nh\n",
    "    JSON_FILE = \"output_samples.json\"\n",
    "    DESCRIPTION = \"\"\"\n",
    "    Dataset vÄƒn phong ThÃ­ch Nháº¥t Háº¡nh Ä‘Æ°á»£c táº¡o tá»« cÃ¡c tÃ¡c pháº©m cá»§a tÃ¡c giáº£.\n",
    "    Format: Alpaca\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Khá»Ÿi táº¡o creator\n",
    "        creator = HuggingFaceDatasetCreator()\n",
    "        \n",
    "        # Äá»c vÃ  xá»­ lÃ½ dataset\n",
    "        print(\"ğŸ“š Äang Ä‘á»c file JSON...\")\n",
    "        data = creator.read_json_dataset(JSON_FILE)\n",
    "        \n",
    "        # Táº¡o vÃ  Ä‘áº©y dataset\n",
    "        print(\"â¬†ï¸ Äang Ä‘Äƒng táº£i dataset lÃªn Hugging Face...\")\n",
    "        creator.create_and_push_dataset(data, JSON_FILE, DESCRIPTION)  # Truyá»n JSON_FILE vÃ o Ä‘Ã¢y\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Lá»—i: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
